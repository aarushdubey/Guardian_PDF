# GuardianPDF - Quick Start Guide

Get GuardianPDF running in under 5 minutes!

## Prerequisites

```bash
# macOS
brew install poppler pybind11 catch2 cmake ollama

# Verify installations
clang++ --version  # Should be 17+
cmake --version    # Should be 4.2+
python3 --version  # Should be 3.10+
```

## Installation

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/guardian_pdf
cd guardian_pdf
```

### 2. Build C++ Module (1 minute)

```bash
cd cpp_engine
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j4
cd ../..
```

**Verify**:
```bash
./cpp_engine/build/test_pdfshredder
# Should show: âœ… All tests passed (11 assertions)
```

### 3. Set Up Python Environment (2 minutes)

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r rag_engine/requirements.txt
pip install -r security_auditor/requirements.txt
```

### 4. Pull LLM Model (1 minute)

```bash
ollama pull llama3.2:latest
```

## Run GuardianPDF

### Start Server

```bash
./start_server.sh
```

Server runs at: `http://localhost:8000`

### Test the System

**Terminal 1** (server running):
```bash
./start_server.sh
```

**Terminal 2** (testing):
```bash
# Test with API client
python test_api.py

# Test security features
python test_security.py

# Or test with curl
curl http://localhost:8000/
```

## Your First Query

### 1. Upload a PDF

```bash
curl -X POST http://localhost:8000/upload_pdf \
  -F "file=@your_document.pdf"
```

Response shows:
- Chunk count
- AI detection summary  
- Integrity verification
- Security warnings (if any)

### 2. Ask Questions

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is this document about?",
    "n_chunks": 3,
    "include_security": true
  }'
```

You'll get:
- âœ… AI-generated answer
- ğŸ“š Source citations
- âš ï¸  Security warnings (if AI-generated content detected)

## Quick Tests

### Test AI Detection

```bash
python test_security.py
```

Expected output:
```
âœ… Human text â†’ Perplexity ~70 â†’ "Uncertain/Human"
âœ… AI text â†’ Perplexity ~25 â†’ "High probability AI"
```

### Test C++ Performance

```python
import sys
sys.path.insert(0, 'cpp_engine/build')
import pdf_shredder

chunks = pdf_shredder.process_pdf("test.pdf")
print(f"Extracted {len(chunks)} chunks")
```

## Troubleshooting

**Ollama not running**:
```bash
ollama serve
# In another terminal:
ollama pull llama3.2:latest
```

**C++ build fails**:
```bash
# Install dependencies
brew install poppler pybind11 catch2

# Clean build
rm -rf cpp_engine/build
cd cpp_engine && mkdir build && cd build
cmake .. && make -j4
```

**Import errors**:
```bash
export PYTHONPATH="${PWD}/cpp_engine/build:${PWD}/rag_engine:${PYTHONPATH}"
```

**Port 8000 in use**:
```bash
# Edit rag_engine/app.py, change port to 8001
uvicorn.run(app, host="0.0.0.0", port=8001)
```

## Next Steps

- ğŸ“– Read the full [README](README.md)
- ğŸ§ª Run all tests: `pytest rag_engine/tests/ -v`
- ğŸ”’ Explore security features: `python test_security.py your.pdf`
- ğŸ“Š Check system stats: `curl http://localhost:8000/stats`

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Your PDF Document              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Module 1: C++  â”‚  (7.5x faster)
       â”‚  PDFShredder    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Module 3:      â”‚  AI Detection
       â”‚  Security       â”‚  Integrity Check
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Module 2:      â”‚  Embeddings
       â”‚  RAG Engine     â”‚  ChromaDB
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
          â”‚  Ollama  â”‚  LLM Answer
          â”‚  (Local) â”‚  + Warnings
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Need Help?

- ğŸ› [Report Issues](https://github.com/yourusername/guardian_pdf/issues)
- ğŸ“§ Email: your.email@example.com
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/guardian_pdf/discussions)

---

**Built with â¤ï¸ for secure, intelligent PDF processing**
